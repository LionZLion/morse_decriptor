{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "595188d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "import json\n",
    "import copy\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c818c376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fd57a6",
   "metadata": {},
   "source": [
    "# Создание буквенного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cfae779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from morse_dataset.morse_dataset import dataset_create\n",
    "\n",
    "dataset_create(size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbe31a6",
   "metadata": {},
   "source": [
    "# Создание и обработка сигнала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d02c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('morse_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b47eedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 45 artists>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAy0AAAGsCAYAAADQY0hSAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAK8dJREFUeJzt3XucVXW9P/73CDIiDCgIKoHgDTAUQlMPaIV3OYja8WFmmoiSYkhxvBR80wALwSyzgkZLLpUikMklTQg4AXqMuBgnMDI1LygQpTA4iIPOzO8PHzM/htvsNcPAZ/T5fDz2Q/dmfdbnvfesWbNea33WZ+eVl5eXBwAAQKIO2N8FAAAA7InQAgAAJE1oAQAAkia0AAAASRNaAACApAktAABA0oQWAAAgaQ33dYdlZWWxdu3aKCgoiLy8vH3dPQAAkIjy8vJ45513ok2bNnHAAbu/nrLPQ8vatWujXbt2+7pbAAAgUWvWrIm2bdvu9t/3eWgpKCiIiA8La9as2b7uHgAASMTmzZujXbt2lRlhd/Z5aKkYEtasWTOhBQAAqPa2ETfiAwAASRNaAACApAktAABA0oQWAAAgaUILAACQNKEFAABImtACAAAkTWgBAACSJrQAAABJE1oAAICkCS0AAEDShBYAACBpmULLiBEjIi8vr8qjc+fOdVUbAABANMzaoEuXLjFv3rz/fwUNM68CAAAgZ5kTR8OGDeOII46oi1oAAAB2kvmelhdffDHatGkTxxxzTFx11VXx+uuv73H5kpKS2Lx5c5UHAABArvLKy8vLc134qaeeiuLi4ujUqVOsW7cuRo4cGW+++WasWrUqCgoKdtlmxIgRMXLkyJ1eLyoqimbNmtW8cthPOgx9MnObV8f0qYNKAADqt82bN0fz5s2rzQaZQsuONm3aFO3bt4/77rsvrr/++l0uU1JSEiUlJVUKa9eundBCvSW0AADsHbmGllrdRX/IIYdEx44d46WXXtrtMvn5+ZGfn1+bbgAAgI+xWn1PS3Fxcbz88stx5JFH7q16AAAAqsgUWm677bZYuHBhvPrqq/Hss8/G5z//+WjQoEFceeWVdVUfAADwMZdpeNgbb7wRV155Zbz11lvRqlWrOPPMM2Px4sXRqlWruqoPAAD4mMsUWqZMmVJXdQAAAOxSre5pAQAAqGtCCwAAkDShBQAASJrQAgAAJE1oAQAAkia0AAAASRNaAACApAktAABA0oQWAAAgaUILAACQNKEFAABImtACAAAkTWgBAACSJrQAAABJE1oAAICkCS0AAEDShBYAACBpQgsAAJA0oQUAAEia0AIAACRNaAEAAJImtAAAAEkTWgAAgKQJLQAAQNKEFgAAIGlCCwAAkDShBQAASJrQAgAAJE1oAQAAkia0AAAASRNaAACApAktAABA0oQWAAAgaUILAACQNKEFAABImtACAAAkTWgBAACSJrQAAABJE1oAAICkCS0AAEDShBYAACBpQgsAAJA0oQUAAEia0AIAACRNaAEAAJImtAAAAEkTWgAAgKQJLQAAQNKEFgAAIGlCCwAAkDShBQAASJrQAgAAJE1oAQAAkia0AAAASRNaAACApAktAABA0oQWAAAgaUILAACQNKEFAABImtACAAAkTWgBAACSJrQAAABJq1VoGTNmTOTl5cWQIUP2UjkAAABV1Ti0LF26NB588MHo2rXr3qwHAACgihqFluLi4rjqqqvi5z//eRx66KF7uyYAAIBKNQotgwYNij59+sS5555b7bIlJSWxefPmKg8AAIBcNczaYMqUKfHcc8/F0qVLc1p+9OjRMXLkyMyFUfc6DH0y0/Kvjumz3/re2/0DAFB/ZLrSsmbNmvj6178ejzzySBx00EE5tRk2bFgUFRVVPtasWVOjQgEAgI+nTFdali9fHhs2bIiTTz658rXS0tJYtGhRjB07NkpKSqJBgwZV2uTn50d+fv7eqRYAAPjYyRRazjnnnFi5cmWV1/r37x+dO3eOb37zmzsFFgAAgNrKFFoKCgrixBNPrPJakyZNomXLlju9DgAAsDfU6sslAQAA6lrm2cN2tGDBgr1QBgAAwK650gIAACRNaAEAAJImtAAAAEkTWgAAgKQJLQAAQNKEFgAAIGlCCwAAkDShBQAASJrQAgAAJE1oAQAAkia0AAAASRNaAACApAktAABA0oQWAAAgaUILAACQNKEFAABImtACAAAkTWgBAACSJrQAAABJE1oAAICkCS0AAEDShBYAACBpQgsAAJA0oQUAAEia0AIAACRNaAEAAJImtAAAAEkTWgAAgKQJLQAAQNKEFgAAIGlCCwAAkDShBQAASJrQAgAAJE1oAQAAkia0AAAASRNaAACApAktAABA0oQWAAAgaUILAACQNKEFAABImtACAAAkTWgBAACSJrQAAABJE1oAAICkCS0AAEDShBYAACBpQgsAAJA0oQUAAEia0AIAACRNaAEAAJImtAAAAEkTWgAAgKQJLQAAQNKEFgAAIGlCCwAAkDShBQAASJrQAgAAJE1oAQAAkia0AAAASRNaAACApAktAABA0oQWAAAgaUILAACQtEyhpbCwMLp27RrNmjWLZs2aRY8ePeKpp56qq9oAAACyhZa2bdvGmDFjYvny5bFs2bI4++yz45JLLonnn3++ruoDAAA+5hpmWbhv375Vno8aNSoKCwtj8eLF0aVLl122KSkpiZKSksrnmzdvrkGZAADAx1Wm0LK90tLS+PWvfx1btmyJHj167Ha50aNHx8iRI2vaTZ3rMPTJTMu/OqbPXm1fG1n73tv912f78+e2v32c3zv7h21u//A3AvgoyXwj/sqVK6Np06aRn58fAwcOjOnTp8cnP/nJ3S4/bNiwKCoqqnysWbOmVgUDAAAfL5mvtHTq1ClWrFgRRUVF8dhjj0W/fv1i4cKFuw0u+fn5kZ+fX+tCAQCAj6fMoaVRo0Zx3HHHRUTEKaecEkuXLo0f/ehH8eCDD+714gAAAGr9PS1lZWVVbrQHAADYmzJdaRk2bFj07t07jjrqqHjnnXdi8uTJsWDBgpgzZ05d1QcAAHzMZQotGzZsiGuuuSbWrVsXzZs3j65du8acOXPivPPOq6v6AACAj7lMoWX8+PF1VQcAAMAu1fqeFgAAgLoktAAAAEkTWgAAgKQJLQAAQNKEFgAAIGlCCwAAkDShBQAASJrQAgAAJE1oAQAAkia0AAAASRNaAACApAktAABA0oQWAAAgaUILAACQNKEFAABImtACAAAkTWgBAACSJrQAAABJE1oAAICkCS0AAEDShBYAACBpQgsAAJA0oQUAAEia0AIAACRNaAEAAJImtAAAAEkTWgAAgKQJLQAAQNKEFgAAIGlCCwAAkDShBQAASJrQAgAAJE1oAQAAkia0AAAASRNaAACApAktAABA0oQWAAAgaUILAACQNKEFAABImtACAAAkTWgBAACSJrQAAABJE1oAAICkCS0AAEDShBYAACBpQgsAAJA0oQUAAEia0AIAACRNaAEAAJImtAAAAEkTWgAAgKQJLQAAQNKEFgAAIGlCCwAAkDShBQAASJrQAgAAJE1oAQAAkia0AAAASRNaAACApAktAABA0oQWAAAgaUILAACQtEyhZfTo0XHqqadGQUFBtG7dOi699NJ44YUX6qo2AACAbKFl4cKFMWjQoFi8eHHMnTs33n///Tj//PNjy5YtdVUfAADwMdcwy8KzZ8+u8nzSpEnRunXrWL58eXz2s5/dq4UBAABEZAwtOyoqKoqIiBYtWux2mZKSkigpKal8vnnz5tp0CQAAfMzUOLSUlZXFkCFD4owzzogTTzxxt8uNHj06Ro4cWdNuPtI6DH0yc5tXx/Spg0rYl2r7c8/afm9uM/t7m63Ne9/Xn/uO7Wtrf/7c67P6/nPfn2xzNbc/91X7U32unfTVePawQYMGxapVq2LKlCl7XG7YsGFRVFRU+VizZk1NuwQAAD6GanSl5eabb44nnngiFi1aFG3btt3jsvn5+ZGfn1+j4gAAADKFlvLy8hg8eHBMnz49FixYEEcffXRd1QUAABARGUPLoEGDYvLkyTFz5swoKCiI9evXR0RE8+bNo3HjxnVSIAAA8PGW6Z6WwsLCKCoqil69esWRRx5Z+Zg6dWpd1QcAAHzMZR4eBgAAsC/VePYwAACAfUFoAQAAkia0AAAASRNaAACApAktAABA0oQWAAAgaUILAACQNKEFAABImtACAAAkTWgBAACSJrQAAABJE1oAAICkCS0AAEDShBYAACBpQgsAAJA0oQUAAEia0AIAACRNaAEAAJImtAAAAEkTWgAAgKQJLQAAQNKEFgAAIGlCCwAAkDShBQAASJrQAgAAJE1oAQAAkia0AAAASRNaAACApAktAABA0oQWAAAgaUILAACQNKEFAABImtACAAAkTWgBAACSJrQAAABJE1oAAICkCS0AAEDShBYAACBpQgsAAJA0oQUAAEia0AIAACRNaAEAAJImtAAAAEkTWgAAgKQJLQAAQNKEFgAAIGlCCwAAkDShBQAASJrQAgAAJE1oAQAAkia0AAAASRNaAACApAktAABA0oQWAAAgaUILAACQNKEFAABImtACAAAkTWgBAACSJrQAAABJE1oAAICkCS0AAEDShBYAACBpmUPLokWLom/fvtGmTZvIy8uLGTNm1EFZAAAAH8ocWrZs2RLdunWLcePG1UU9AAAAVTTM2qB3797Ru3fvuqgFAABgJ5lDS1YlJSVRUlJS+Xzz5s113SUAAPARUuehZfTo0TFy5Mi67oZ9rMPQJzO3eXVMn/3W/97sm5rb39vN/rQ/t9nafu77++dWn3/fa1P7/v7ca2t/vvd93b4+f+4R6bz3/V27bTZtdT572LBhw6KoqKjysWbNmrruEgAA+Aip8yst+fn5kZ+fX9fdAAAAH1G+pwUAAEha5istxcXF8dJLL1U+f+WVV2LFihXRokWLOOqoo/ZqcQAAAJlDy7Jly+Kss86qfH7LLbdERES/fv1i0qRJe60wAACAiBqEll69ekV5eXld1AIAALAT97QAAABJE1oAAICkCS0AAEDShBYAACBpQgsAAJA0oQUAAEia0AIAACRNaAEAAJImtAAAAEkTWgAAgKQJLQAAQNKEFgAAIGlCCwAAkDShBQAASJrQAgAAJE1oAQAAkia0AAAASRNaAACApAktAABA0oQWAAAgaUILAACQNKEFAABImtACAAAkTWgBAACSJrQAAABJE1oAAICkCS0AAEDShBYAACBpQgsAAJA0oQUAAEia0AIAACRNaAEAAJImtAAAAEkTWgAAgKQJLQAAQNKEFgAAIGlCCwAAkDShBQAASJrQAgAAJE1oAQAAkia0AAAASRNaAACApAktAABA0oQWAAAgaUILAACQNKEFAABImtACAAAkTWgBAACSJrQAAABJE1oAAICkCS0AAEDShBYAACBpQgsAAJA0oQUAAEia0AIAACRNaAEAAJImtAAAAEkTWgAAgKQJLQAAQNKEFgAAIGlCCwAAkDShBQAASJrQAgAAJK1GoWXcuHHRoUOHOOigg+L000+PJUuW7O26AAAAIqIGoWXq1Klxyy23xPDhw+O5556Lbt26xQUXXBAbNmyoi/oAAICPuYZZG9x3333xla98Jfr37x8REQ888EA8+eSTMWHChBg6dOhOy5eUlERJSUnl86KiooiI2Lx5c01r3qvKSt7NtPyOddemfda2+7v9R6X22rb33rNJ5b3X59pr2957zyaV916fa69te+89m1Tee32uvbbt6/t7358qaikvL9/jcnnl1S2xnW3btsXBBx8cjz32WFx66aWVr/fr1y82bdoUM2fO3KnNiBEjYuTIkbl2AQAAfMysWbMm2rZtu9t/z3Sl5d///neUlpbG4YcfXuX1ww8/PP72t7/tss2wYcPilltuqXxeVlYWb7/9drRs2TLy8vKydL/PbN68Odq1axdr1qyJZs2a1av2aq+f7etz7bVtr/b62b4+117b9mqvn+3rc+21ba/2+tl+f9e+r5SXl8c777wTbdq02eNymYeHZZWfnx/5+flVXjvkkEPqutu9olmzZrX6Ie/P9mqvn+3rc+21ba/2+tm+Ptde2/Zqr5/t63PttW2v9vrZfn/Xvi80b9682mUy3Yh/2GGHRYMGDeKf//xnldf/+c9/xhFHHJGtOgAAgBxkCi2NGjWKU045JebPn1/5WllZWcyfPz969Oix14sDAADIPDzslltuiX79+sWnP/3pOO200+L++++PLVu2VM4m9lGQn58fw4cP32lYW31or/b62b4+117b9mqvn+3rc+21ba/2+tm+Ptde2/Zqr5/t93ftqck0e1iFsWPHxr333hvr16+PT33qU/HjH/84Tj/99LqoDwAA+JirUWgBAADYVzLd0wIA9d2Pf/zj2LRpU7z//vvxs5/9bKfJZQBIj9BCEn76059Gly5dIiKiZ8+ecffdd+/nioCPqvXr10fLli2jcePGMXXq1GjRosX+LgmAahgeRhKKiopi06ZN0b59+1izZk00adLEgQRQZzZt2hTvvfee6foB6gmhBQDqkbfeeitOOOGEWLJkSXTo0GF/lwPUkS9+8Ytx6qmnxq233rq/S0mC4WHb6dChQ+Tl5e30GDRoULVtr7322l22bdu27T6ovGr/jRo1iuOOOy7uuuuu+OCDD3Jqe+mll+70+oIFCyIvLy82bdpU7ToGDBgQxx9/fBx88MFx6KGHRo8ePeLhhx/OXPv2jwsvvDCn9rW1aNGi6Nu3b7Rp0yby8vJixowZmdrvzfrHjBkTeXl5MWTIkD0uN2DAgCp97ernl7Xuli1bxoUXXhh/+ctfcm47cODAnf5t0KBBkZeXF9dee+0e11FaWhp33XVXdOzYMRo3blyllgULFlRbw4gRI3b6zDt37lxtu4iI0aNHx6mnnhoFBQXRunXruPTSS+OFF17Iqe3eUFpaGnfeeWccffTR0bhx4zj22GPjO9/5TqR+Dml3+4oK999/f+aD6P79+8cdd9yRqc0f//jHaNCgQfTp0ydTu13V/9prr8VBBx0UeXl5mdZ1zTXXRN++ffdL36NGjYpLLrkk02fdoUOHuP/++6u8lmUfX6FXr17V7p92VFpaGj179oz/+q//qvJ6UVFRtGvXLr71rW/tsf3u9rEVj1zqHzNmTHTp0iUOPvjg6NixY0yePHm3y/7973+Pww8/PG666aYqr+/q83rvvffirLPOiu7du++xjvXr18fgwYPjmGOOifz8/GjXrl307du3yvfe1ZU333wzrr766sohkSeddFIsW7aszvutrcLCwujatWvlt7n36NEjnnrqqczr2d12U9feeeedGDJkSLRv3z4aN24cPXv2jKVLl2Zaxx133BGjRo2KoqKiTO2q21fXV0LLdpYuXRrr1q2rfMydOzciIi6//PKc2l944YVV2q9bty7+/Oc/12XJu+z/xRdfjFtvvTVGjBgR99577z7pu2XLlvHQQw/Fiy++GEuWLImbbropBg4cGA888EBO7Xf12T366KN1XPWHtmzZEt26dYtx48bVeB17o/6lS5fGgw8+GF27dq122fvuu6+yny984Qs1LbtK3fPnz4+GDRvGRRddlFPbdu3axZQpU2Lr1q2Vr7333nsxefLkOOqoo6pt//3vfz++853vxDe+8Y1YvXp1rFu3LnNw6NKlS5XP/Jlnnsmp3cKFC2PQoEGxePHimDt3brz//vtx/vnnx5YtWzL1X1P33HNPFBYWxtixY2P16tVxzz33xPe+9734yU9+Uif97eoP2O4OWHd1cFtXSktL44knnoiLL744U7vx48fH4MGDY9GiRbF27dpa1XDnnXfmfADz/PPPxxVXXBFt27aNX/3qV/HEE09EQUFB9O7du/LvRV31XeHdd9+N8ePHx/XXX5+5v/2lQYMGMWnSpJg9e3Y88sgjla8PHjw4WrRoEcOHD692Hbvax/7mN7/JuYann346fvjDH8aqVavi6quvjmuuuSb+8Y9/7HLZjh07xuzZs+PRRx+NYcOG7XadH3zwQVx++eWxdu3amDNnThxyyCG7XO7VV1+NU045Jf7nf/4n7r333li5cmXMnj07zjrrrJxOilbo1atXTJo0KeflIyI2btwYZ5xxRhx44IHx1FNPxV//+tf4wQ9+EIceemim9dREbU+Itm3bNsaMGRPLly+PZcuWxdlnnx2XXHJJPP/885lrmThxYuV2M3HixJzabNq0aZdhZ3c/5x0NGDAg5s6dG7/61a9i5cqVcf7558e5554bb775Zs51n3jiiXHsscfmfBL4oy7zl0t+lLVq1arK8zFjxsSxxx4bn/vc53Jqn5+fv1/HR2/f/0033RTTp0+PWbNm7XGnu7fcc889VZ4ff/zxMWPGjFi0aNEuz8bvaH9+dr17947evXvXah21rb+4uDiuuuqq+PnPfx7f/e53q12+4sxTRETjxo2jpKSkRv1uX/cRRxwRQ4cOjc985jPxr3/9a6ffhx2dfPLJ8fLLL8fjjz8eV111VUREPP7443HUUUfF0UcfXW3fzzzzTHTt2jUGDBhQ+dpBBx2Uqf6GDRvW6HOfPXt2leeTJk2K1q1bx/Lly+Ozn/1s5vVl9eyzz8Yll1xSeaWgQ4cO8eijj8aSJUvqvO+UPPvss3HggQfGqaeemnOb4uLimDp1aixbtizWr18fkyZNiv/3//5fjfpfuXJlPPLII3HrrbdWe4Jn+vTpcfnll8dFF10UDz/8cBQWFsbmzZvjW9/6VowfPz7OP//8GDt2bM4HoVn63t7vfve7yM/Pj//4j//IuU1E7JMzy3vSsWPHGDNmTAwePDjOPvvsWLJkSUyZMiWWLl0ajRo1qrb9rvaxWe57fPLJJyv//+abb47hw4fH2rVr45hjjtnl8t27d48nn3wyzj///Dj00EPjG9/4RpV/Lysri379+sX//d//xTPPPBOtW7febd9f/epXIy8vL5YsWRJNmjSpfL1Lly5x3XXX5fweauKee+6Jdu3aVTlQz2X/nIIdr2SOGjUqCgsLY/HixZUT91SnYrRJixYtKrefXENHhd/85jfRs2fPiIiYOnVqTiF769at8Zvf/CZmzpxZ+TdlxIgR8dvf/jYKCwtz+jtfoW/fvjFlypRMAfejypWW3di2bVs8/PDDcd111+33nX1NNW7cOLZt27bP+y0vL4/ly5fHs88+u8+GeNV3gwYNij59+sS5556732ooLi6Ohx9+OI477rho2bJlTm2uu+66Kn8MJ0yYEP3798+pbdeuXWP16tWxYMGCGg+LevHFF6NNmzZxzDHHxFVXXRWvv/56jdZTcem9JpM/TJo0KfM+omfPnjF//vz4+9//HhFReeBT2/Bc38yaNSv69u2b6fObNm1adO7cOTp16hRXX311TJgwocbbz9ChQ6Nv376VByR7MmTIkOjVq1fMmDEjevXqFY0bN478/Pw488wzY+LEiXHttdfGN77xjZyv1mXpe3tPP/10nHLKKZnaREQcdthh8e9//ztzu71p8ODB0a1bt/jyl78cN9xwQ3z729+Obt267dMaysvL49Zbb40TTzwxTjvttD0ue8YZZ8Tjjz8ed955Zzz44INV/m3QoEExd+7cmDdv3h6vLL/99tsxe/bsGDRoUJXAUiHrAXRWs2bNik9/+tNx+eWXR+vWraN79+7x85//vE77rAulpaUxZcqU2LJlS/To0SPndhXHQLkE4x1VBJ6WLVvGEUccEUcccUQ0b94857alpaU7nYhr3LhxziMCKpx22mmxZMmSGp+c/CgRWnZjxowZsWnTpmrH5W/viSeeiKZNm0bTpk2jbdu2cd5558Xvf//7TP0+8sgjleto2rRpPP300xkr/3CnPG/evJgzZ06cffbZmWuveGQ9gJoxY0Y0bdo0GjVqFKeeemrceOONcc0119S4//o07XFt6p8yZUo899xzMXr06L3Sf9u2bePcc8+NOXPmZGpXUFAQs2bNiqlTp8YBB+S2a7j66qvjmWeeiddeey1ee+21+N///d+4+uqrc2o7fPjwGDx4cFx22WWRn59fWXuuTj/99MohJ4WFhfHKK6/EZz7zmXjnnXdyXkfEh2dMhwwZEmeccUaceOKJmdpGRDRv3jw6deqUqc3QoUPji1/8YnTu3DkOPPDA6N69ewwZMqTyilXK9sZ+rsLMmTNrNDSsYhu78MILo6ioKBYuXJi570WLFsWcOXNy+r375z//Ga+//voeh05efPHF8e6778aqVav2at87eu2116JNmzaZ25155pnx6KOP1jjY7w15eXlRWFgY8+fPj8MPPzyGDh26z2sYMGBAPPvsszF79uycDmSbN28eZWVlMXjw4JgyZUpERAwbNiweeuihKC0trTZ0vPTSS1FeXp7z/XZ72z/+8Y8oLCyM448/PubMmRM33XRTfO1rX4tf/OIX+6WerFauXBlNmzaN/Pz8GDhwYEyfPj0++clP5tx+48aNERHRtGnTzH1XhIT8/PzMbQsKCqJHjx7xne98J9auXRulpaXx8MMPxx//+MdYt25dpnW1adMmtm3bFuvXr8/Ubm/uq1NheNhujB8/Pnr37p3pj8NZZ50VhYWFEfHh2ZWxY8dGnz594plnnonTTz89p3VcfPHFVZb9xCc+kXP/FRvo+++/H2VlZfGlL30pRowYkbn2Cn/6059yPgCNiDjvvPNixYoVUVxcHH/605/im9/8Zhx55JE5DQ/bVf/1acrjmta/Zs2a+PrXvx5z587NPDRqd/3vuO3taRjJ9u02btwYP/3pT6N3796xZMmSaN++fbX9tmrVKvr06ROTJk2K8vLy6NOnTxx22GE51dyoUaO455574u23346FCxfGk08+GcXFxXHyySfn1H77UN21a9c4/fTTo3379jFt2rRM4/0HDRoUq1atynz2q8LnP//5+PznP5+pzbRp0+KRRx6JyZMnR5cuXWLFihUxZMiQaNOmTfTr169Gdewru9pmKra1LFavXh1r166Nc845J+c2L7zwQixZsiSmT58eER8OD7ziiiti/Pjx0atXr0z9Dx06NPr16xcnnHBCtfdSVRzcvvvuu7tdpuLfcvk9ztL3jrZu3VqjfcUdd9wRf/nLX6J9+/aVZ/xLS0szr6e2JkyYEAcffHC88sor8cYbb+zT2c+WLl0aEyZMiL/97W85/W3dtm1bDBgwIAYOHBjdunWLr3zlKxER8Ytf/CLmz58fd9xxR9x8880xbdq03a6jNpNr3H333VVOfm3dujUWL14cN998c+Vrf/3rX/d4paesrCw+/elPV66ne/fusWrVqnjggQeS39dERHTq1ClWrFgRRUVF8dhjj0W/fv1i4cKFOQeXigP9ww8/PHPfb7/9dkR8GEBq4le/+lVcd9118YlPfCIaNGgQJ598clx55ZWxfPnyTOtp3LhxROx5/7Mre9pX53pMmhqhZRdee+21mDdvXjz++OOZ2jVp0iSOO+64yucTJkyIxx9/PGbMmJHzBlJQUFDjX5CKDbRRo0bRpk2baNgw9x/vjrVHRLzxxhuZ+t9+HZ/61KfiX//6V3z/+9/PKbTsqv/6pKb1L1++PDZs2FDlQL20tDQWLVoUY8eOjZKSkmjQoEHm/rff9vYUWnZs99BDD0Xz5s1zvrcm4sMhYhV/RLNOZvD888/HxIkTY9q0aXH88cdnmsVoR4ccckh07NgxXnrppZzb3HzzzfHEE0/EokWL9tlMfxERt99+e+XVloiIk046KV577bUYPXp08gcSu9pmHnvssZgxY0amA4NZs2bFeeedl+kAfPz48fHBBx9UOZlUXl4e+fn5MXbs2JyHbkyfPj3+/Oc/7/Fgc3uHHnponH766fHLX/4yvv71r+80zOeDDz6IBx98MNq2bVvt1bqsfe/osMMOqzx7nEXLli1j/vz5sXHjxnjrrbciIvuJqdp69tln44c//GH8/ve/j+9+97tx/fXXx7x58/bZEOyKSRtyvTI6atSoKC4ujtGjR0fTpk1j3bp18e1vfzumTp0an/3sZ+Ohhx6Kbt26xcyZM+OSSy7Z5TqOP/74yMvLi7/97W+Z6x04cGCViVauuuqquOyyy6rMwlbdidUjjzxypwP8E044IdMkBvtTxWyoERGnnHJKLF26NH70ox/tNFxvd1avXh2NGjWq0X08FTfMH3nkkZnbRkQce+yxsXDhwtiyZUts3rw5jjzyyLjiiit2ex/V7lSEp+ruM93RnvbVQstHyMSJE6N169aZp9Pc0QEHHBAHHHDAPjubldqBf3l5eZSVle3vMpJ2zjnnxMqVK6u81r9//+jcuXN885vfzCmw7ErFtpf1LF9eXl4ccMABVWYEq86FF14Y27Zti7y8vLjgggsy9Xf77bdHjx49dpoKtSaKi4vj5Zdfji9/+cvVLlteXh6DBw+O6dOnx4IFC/b5janvvvvuTkPwGjRoUG9/X2ryuz5z5sy44YYbcl7+gw8+iF/+8pfxgx/8IM4///wq/3bppZfGo48+mtMJktLS0vjWt74VgwcPzhRUH3roobjooovihBNOiOuvvz5eeeWVePfdd+Puu++OX/7yl7Fhw4aYMWPGHn9na9r39rp3716rmYQOPfTQypmjsp6YioicpiPflXfffTeuvfbauOmmm+Kss86Ko48+Ok466aR44IEHdppauK587nOfy3nK2VWrVsWYMWNi1qxZlUOLPvOZz1T5b8eOHWP48OHx1a9+NXr16rXL0NyiRYu44IILYty4cfG1r31tp8C7adOm3Q4xa9GiRZUr9o0bN47WrVtn+jt/xhln7HQ17+9//3tOV9JTVFZWlunejt/97nfRs2fPTCdxK/z1r3+NVq1a1XrUR5MmTaJJkyaxcePGmDNnTnzve9/L1H7VqlXRtm3bnEcx7El9Py4TWnZQVlYWEydOjH79+mXeyEtKSiovRW7cuDHGjh0bxcXF8Z//+Z91UWoyNm/eHAMGDIgbbrghOnXqFFu3bo2nn3467r333py/f2H7z67CgQcemPMN4RXGjh0b06dPzzT3fXFxcZWz86+88kqsWLEiWrRokdPUvRG7rr9hw4bV7mQKCgp2OjPbpEmTaNmyZab7K7bv/+23344f//jHsWXLlmqnL97dNpvl+ycaNGgQq1evrvz/XM2fPz9mz54dixcvzrnN9m677bbo27dvtG/fPtauXRvDhw+PBg0axJVXXllt20GDBsXkyZNj5syZUVBQUPkZNG/evPJSfK6mT58ew4YNy3QmtW/fvjFq1Kg46qijokuXLvHnP/857rvvvjqfSWhvKC4urnyvFUMOtm7dGhdddFHOwx42bNgQy5Yti1mzZuXc7xNPPBEbN26M66+/fqeDw8suuyzGjx+fU2iZN29eHHTQQZlnVTzxxBPjhRdeiIkTJ8YzzzwTq1evjvfffz/++Mc/xnXXXRf9+/ev9kxoTfve3gUXXBDDhg2LjRs37pNpa3d0zjnnxLnnnpv5PQwbNizKy8tjzJgxEfHhjHnf//7347bbbovevXvvk2Fif/jDH3L6XS0rK4sBAwbEF7/4xWpPxNx2220xbdq0uO2223Z7g/u4cePijDPOiNNOOy3uuuuu6Nq1a3zwwQcxd+7cKCwsrNx/1oX//u//jp49e8bdd98dX/jCF2LJkiXxs5/9LH72s5/VWZ97y7Bhw6J3795x1FFHxTvvvBOTJ0+OBQsW5HS/5tq1a+P++++PadOmVZk5Lov58+dnnihje3PmzIny8vLo1KlTvPTSS3H77bdH586dc56spsLTTz+904maXOxpX11fCS07mDdvXrz++us1OniYPXt25WXEgoKCOP7442Py5MmZx1rXNwcddFC0bNkybr311nj11VejQYMGcdJJJ8X48eNz/o6b7T+7Cl26dMnpptbt/fvf/46XX345U5tly5bFWWedVfn8lltuiYiIfv365Twn/q7q79SpU42GBNTEjtte586dY9q0aZVnBLO0+/Wvf515m62YfjlXZWVlcdttt8UVV1xR7Qw+u/PGG2/ElVdeGW+99Va0atUqzjzzzFi8eHFOl9Arxvnu+D4rZoHKoqioKPN9CT/5yU/izjvvjK9+9auxYcOGaNOmTdx4443x7W9/O9N6Jk2aFP3798/pilpRUVGsWLGi8nlFUF+5cmWVIanbtm2LN998M15//fVdhvb58+fHCSecEBE7b2u5hpbf/va3cdppp2U6czh+/Pg499xzd3k2+7LLLovvfe978Ze//KXa7zl67733Yvjw4TU64K+4GXjgwIFx7bXXxqZNmzJ9GW1t+q5w0kknxcknnxzTpk2LG2+8scbrqamXX345TjrppExtFi5cGOPGjYsFCxbEwQcfXPn6jTfeGI8//vg+GyaW6+/qj370o3j11Vfjd7/7XbXLNmzYMCZMmBCnnXZafOlLX6ryt6TCMcccE88991yMGjUqbr311li3bl20atUqTjnllJ3uhdzbTj311MoTK3fddVccffTRcf/99++zST923O9EVN33dO/efbc3yW/YsCGuueaaWLduXTRv3jy6du0ac+bMifPOO6/afidPnhzLli2L2bNnZ56Vc+vWrTF58uR46qmnYty4cVVOSBYVFUV5eXmsX78+WrVqtccTdUVFRTFs2LB44403okWLFnHZZZfFqFGj4sADD8y5lvfeey9mzJix0zT9udjTvrq+yitP/SuYAdil4cOHx8KFC6sdsnPttddmni0oS2jP6uKLL44zzzxzp+++IDdPPvlk3H777bFq1aqcZ/qDfS2X/c4f/vCH5E7sVpwMqs4rr7xS51cICwsLY/r06fV+1q+9xd4OoJ566qmnchofXTG7W66PXL48rTbOPPPMnIbxsWt9+vSJG264IdM3a8O+Vt1+J+X7aj73uc/tsfZ95cADD4yf/OQn+6y/1BkeBlBPLVmypE7We8QRR9TpzZqusNTekCFD9ncJUCuf/OQna/T9KXWtcePG1d58f/jhh9d4opwsBgwYUOd91CeGhwEAAEkzPAwAAEia0AIAACRNaAEAAJImtAAAAEkTWgAAgKQJLQAAQNKEFgAAIGlCCwAAkLT/DzA2eVOayReyAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_char = Counter()\n",
    "\n",
    "for mess in train_df['message']:\n",
    "    count_char.update(mess)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.bar(count_char.keys(), count_char.values())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08012051",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_params = {\n",
    "    'dt': 3000,\n",
    "    'nu': 1000,\n",
    "    'fs': 48000,\n",
    "    'step': 50,\n",
    "    'size': 960,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ec2e7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from morse_dataset.wav_morse import wav_save\n",
    "# dt - Число отсчётов. Время точки = dt / 48000\n",
    "dt = 3000\n",
    "# Частота\n",
    "nu = 1000\n",
    "# Частота дискретизации\n",
    "fs = 48000\n",
    "\n",
    "train_df = wav_save(\n",
    "    dt=dict_params['dt'],\n",
    "    nu=dict_params['nu'], \n",
    "    noise=True, \n",
    "    dataset_path='morse_dataset.csv',\n",
    "    fs=dict_params['fs']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f044623",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from stft import fft_morse\n",
    "\n",
    "\n",
    "train_df['fft'] = train_df['signal'].progress_apply(\n",
    "    fft_morse,\n",
    "    step=dict_params['step'], \n",
    "    size=dict_params['size'],\n",
    "    nu=dict_params['nu']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c4ed68",
   "metadata": {},
   "source": [
    "Кодировка сообщения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd2c6fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CTC_decoder import coding_char\n",
    "\n",
    "train_df['coding_message'] = train_df['message'].apply(coding_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c863e1db",
   "metadata": {},
   "source": [
    "# Нейронная сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e14e62",
   "metadata": {},
   "source": [
    "Разбиение на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8f8f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df['fft']\n",
    "y = train_df['coding_message']\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665f57c0",
   "metadata": {},
   "source": [
    "# Датасеты и даталодеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "868def6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Band_Dataset(data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.y = y\n",
    "        self.X = X\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        band_signal = torch.tensor(self.X.iloc[idx])\n",
    "        target = torch.tensor(self.y.iloc[idx])\n",
    "        target_length = len(target)\n",
    "        input_length = band_signal.shape[0]\n",
    "        return band_signal, target, target_length, input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36a06d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    signals, targets, target_lengths, input_lengths = zip(*batch)\n",
    "    targets_cat = torch.cat(targets)\n",
    "    signals_cat = torch.nn.utils.rnn.pad_sequence(signals, batch_first=True).float()\n",
    "\n",
    "    return {\n",
    "        'signals': signals_cat.unsqueeze(1),\n",
    "        'targets': targets_cat,\n",
    "        'input_lengths': torch.tensor(input_lengths),\n",
    "        'target_lengths': torch.tensor(target_lengths)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99a3d5f",
   "metadata": {},
   "source": [
    "# Проектирование нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41b49edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Morse_Decoder(nn.Module):\n",
    "    def __init__(self, num_char):\n",
    "        super(Morse_Decoder, self).__init__()\n",
    "        self.hidden_layer = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=401, stride=15, padding=200),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Softplus(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Conv1d(64, 64, kernel_size=21, stride=1, padding=10),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Softplus(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Conv1d(64, 64, kernel_size=11, stride=1, padding=5),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Softplus(),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=64,\n",
    "            hidden_size=64,\n",
    "            num_layers=2, \n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(128, num_char),\n",
    "        )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # batch, channel, time\n",
    "        x = self.hidden_layer(inp)\n",
    "        # batch, time, channel\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        # time, batch, channel\n",
    "        x = x.permute(1, 0, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1414c24",
   "metadata": {},
   "source": [
    "# Настройка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c50b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('morse_dict.json', 'r') as file:\n",
    "    morse_code = json.load(file)\n",
    "model = Morse_Decoder(len(morse_code)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85b0f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CTCLoss(blank=0)\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0b2feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Band_Dataset(X_train, y_train)\n",
    "train_loader = data.DataLoader(train_dataset,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=True,\n",
    "                               collate_fn=collate_fn,\n",
    "                               )\n",
    "\n",
    "train_val_dataset = Band_Dataset(X_val, y_val)\n",
    "train_loader_val = data.DataLoader(train_val_dataset,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=False,\n",
    "                                   collate_fn=collate_fn\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c4e028",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "993ac91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], loss_mean=234.111, last loss_val: 9999.000, lr=[0.001]: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "Epoch [2/100], loss_mean=232.204, last loss_val: 199.632, lr=[0.001]: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "Epoch [3/100], loss_mean=231.241, last loss_val: 188.219, lr=[0.001]: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "Epoch [4/100], loss_mean=230.412, last loss_val: 188.505, lr=[0.001]: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "Epoch [5/100], loss_mean=230.972, last loss_val: 188.464, lr=[0.001]: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "Epoch [6/100], loss_mean=227.874, last loss_val: 188.098, lr=[0.001]: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "Epoch [7/100], loss_mean=227.862, last loss_val: 187.904, lr=[0.001]: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     32\u001b[0m     batch_dict_val \u001b[38;5;241m=\u001b[39m {k: n\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k,n \u001b[38;5;129;01min\u001b[39;00m batch_dict_val\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m---> 33\u001b[0m     predict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_dict_val\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msignals\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     predict \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlog_softmax(predict, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     35\u001b[0m     input_lengths \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((predict\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], ), predict\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[13], line 40\u001b[0m, in \u001b[0;36mMorse_Decoder.forward\u001b[1;34m(self, inp)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# batch, time, channel\u001b[39;00m\n\u001b[0;32m     38\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(x)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# time, batch, channel\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\rnn.py:1124\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1121\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1124\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1138\u001b[0m         batch_sizes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m   1146\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Q_val = 9999\n",
    "best_loss = 9999\n",
    "model.to(device)\n",
    "\n",
    "for _e in range(epochs):\n",
    "    model.train()\n",
    "    loss_mean = 0\n",
    "    lm_count = 0\n",
    "    train_tqdm = tqdm(train_loader, leave=True)\n",
    "    for batch_dict in train_tqdm:\n",
    "        batch_dict = {k: n.to(device) for k, n in batch_dict.items()}\n",
    "        predict = model(batch_dict['signals'])\n",
    "        predict = nn.functional.log_softmax(predict, dim=2)\n",
    "        input_lengths = torch.full((predict.shape[1], ), predict.shape[0])\n",
    "        loss = loss_func(predict, batch_dict['targets'], input_lengths, batch_dict['target_lengths'])\n",
    "\n",
    "        assert not torch.isnan(loss).any()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        lm_count += 1\n",
    "        loss_mean = 1/lm_count * loss.item() + (1 - 1/lm_count) * loss_mean\n",
    "        train_tqdm.set_description(f\"Epoch [{_e+1}/{epochs}], loss_mean={loss_mean:.3f}, last loss_val: {Q_val:.3f}, lr={scheduler.get_last_lr()}\")\n",
    "\n",
    "    model.eval()\n",
    "    # Валидационная выборка\n",
    "    lm_count_val = 0\n",
    "    loss_mean_val = 0\n",
    "    for batch_dict_val in train_loader_val:\n",
    "        with torch.no_grad():\n",
    "            batch_dict_val = {k: n.to(device) for k,n in batch_dict_val.items()}\n",
    "            predict = model(batch_dict_val['signals'])\n",
    "            predict = nn.functional.log_softmax(predict, dim=2)\n",
    "            input_lengths = torch.full((predict.shape[1], ), predict.shape[0])\n",
    "            loss = loss_func(predict, batch_dict_val['targets'], input_lengths, batch_dict_val['target_lengths'])\n",
    "\n",
    "            lm_count_val += 1\n",
    "            loss_mean_val = 1/lm_count_val * loss.item() + (1 - 1/lm_count_val) * loss_mean_val\n",
    "    Q_val = loss_mean_val\n",
    "\n",
    "    # early stopping\n",
    "    if Q_val < best_loss:\n",
    "        best_loss = Q_val\n",
    "        torch.save(model.state_dict(), f'best_model.tar')\n",
    "        patience = 15\n",
    "    else:\n",
    "        patience -= 1\n",
    "        if patience == 0:\n",
    "            print(\"Stop! Loss val don't drop!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00620cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3, 48, 48, 48, 48, 48, 48, 48,  3,  3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33409f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['В']\n"
     ]
    }
   ],
   "source": [
    "from morse_dataset.word_to_morse import morse_generator\n",
    "from CTC_decoder import CTC_decoder\n",
    "from stft import fft_morse\n",
    "from model_class import Morse_Decoder\n",
    "\n",
    "msg = 'привет'\n",
    "# dt - Число отсчётов. Время точки = dt / 48000\n",
    "dt = 3000\n",
    "# Частота\n",
    "nu = 1000\n",
    "# Частота дискретизации\n",
    "fs = 48000\n",
    "step = 50\n",
    "size = 960\n",
    "\n",
    "signal = morse_generator(msg, dt, nu, noise=True, dev=0.5)\n",
    "signal = np.float32(signal / np.max(np.abs(signal)))\n",
    "fft_transform = fft_morse(signal, step=step, size=size, nu=nu, fs=fs)\n",
    "signal_stft = torch.tensor(fft_transform, dtype=torch.float)\n",
    "\n",
    "model = Morse_Decoder(57)\n",
    "weights = torch.load('best_model.tar', weights_only=True)\n",
    "model.load_state_dict(weights)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predict = model(signal_stft.unsqueeze(0).unsqueeze(0))\n",
    "    predict = nn.functional.log_softmax(predict, dim=-1)\n",
    "    pred_indices = torch.argmax(predict, dim=-1)\n",
    "    pred_indices = pred_indices.permute(1, 0).squeeze(0)\n",
    "    main_answer = CTC_decoder(pred_indices)\n",
    "    \n",
    "print(main_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "210833d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В\n"
     ]
    }
   ],
   "source": [
    "from  neural import morse_processing\n",
    "\n",
    "msg = 'Привет'\n",
    "print(*morse_processing(msg, dev=0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
